{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from decision_transformer.models.decision_transformer import DecisionTransformer\n",
    "from qoe_to_go import QoE_predictor_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import envs.fixed_env_vmaf as env_test\n",
    "from utils.data_loader import get_throughput_char, get_qoe2go_estimation\n",
    "\n",
    "M_IN_K = 1000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load QoE2Go prediction models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QoE_predictor_model(\n",
       "  (QoE_predictor_model): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=128, out_features=32, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_id = 'cuda:0'\n",
    "device = torch.device(device_id if torch.cuda.is_available() else \"cpu\")\n",
    "q2go_model = QoE_predictor_model().to(device)\n",
    "\n",
    "model_checkpoint_path = \"./checkpoints/q2go/Q2GO_predictor.pt\"\n",
    "q2go_model.load_state_dict(torch.load(model_checkpoint_path))\n",
    "q2go_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load environment of abr (vmaf version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_traces = '../test_traces/'\n",
    "log_save_dir = './results_valid/'\n",
    "if not os.path.exists(log_save_dir):\n",
    "    os.mkdir(log_save_dir)\n",
    "log_path_ini = log_save_dir + 'log_test_karmar' \n",
    "\n",
    "video_size_file = '../video_size/ori/video_size_' #video = 'origin'\n",
    "video_vmaf_file = './video_vmaf/chunk_vmaf'\n",
    "from utils import load_trace\n",
    "all_cooked_time, all_cooked_bw, all_file_names = load_trace.load_trace(test_traces)\n",
    "test_env = env_test.Environment(all_cooked_time=all_cooked_time,\n",
    "                                all_cooked_bw=all_cooked_bw, \n",
    "                                all_file_names = all_file_names, \n",
    "                                video_size_file = video_size_file, \n",
    "                                video_psnr_file= video_vmaf_file\n",
    "                                )\n",
    "\n",
    "S_INFO = 7 # \n",
    "S_LEN = 8 # maximum length of states \n",
    "C_LEN = 0 # content length \n",
    "S_DIM = 16\n",
    "VIDEO_BIT_RATE = [300,750,1200,1850,2850,4300]  # kbps\n",
    "TOTAL_CHUNK_NUM = 49\n",
    "QUALITY_PENALTY = 0.8469011 #dB\n",
    "REBUF_PENALTY = 28.79591348\n",
    "SMOOTH_PENALTY_P = -0.29797156\n",
    "SMOOTH_PENALTY_N = 1.06099887\n",
    "test_env.set_env_info(S_INFO, S_LEN, C_LEN, TOTAL_CHUNK_NUM, VIDEO_BIT_RATE, \\\n",
    "                    QUALITY_PENALTY, REBUF_PENALTY, \\\n",
    "                    SMOOTH_PENALTY_P, SMOOTH_PENALTY_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load dt model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTransformer(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(1, 32)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): Block(\n",
       "        (ln_1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (ln_1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (ln_1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (embed_timestep): Embedding(512, 32)\n",
       "  (embed_return): Linear(in_features=1, out_features=32, bias=True)\n",
       "  (embed_state): Linear(in_features=16, out_features=32, bias=True)\n",
       "  (embed_action): Linear(in_features=6, out_features=32, bias=True)\n",
       "  (embed_ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "  (predict_state): Linear(in_features=32, out_features=16, bias=True)\n",
       "  (predict_action): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=6, bias=True)\n",
       "    (1): Softmax(dim=-1)\n",
       "  )\n",
       "  (predict_return): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model    \n",
    "dt_model_checkpoint_path = \"./checkpoints/dt/dt_model.pt\"\n",
    "\n",
    "dt_model = DecisionTransformer(\n",
    "    state_dim=S_DIM,\n",
    "    act_dim=len(VIDEO_BIT_RATE),\n",
    "    max_length=4,\n",
    "    max_ep_len=512,\n",
    "    action_tanh=False,\n",
    "    hidden_size=32,\n",
    "    n_layer=3,\n",
    "    n_head=1,\n",
    "    n_inner=4 * 32,\n",
    "    activation_function='relu',\n",
    "    n_positions=1024,\n",
    "    resid_pdrop=0.1,\n",
    "    attn_pdrop=0.1,\n",
    ").to(device)\n",
    "\n",
    "dt_model.load_state_dict(torch.load(dt_model_checkpoint_path))\n",
    "dt_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "simulation of a session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DEFAULT_QUALITY = 1\n",
    "bit_rate = DEFAULT_QUALITY\n",
    "last_bit_rate = DEFAULT_QUALITY\n",
    "last_quality = test_env.chunk_psnr[DEFAULT_QUALITY][0]\n",
    "state_dim = S_DIM\n",
    "a_dim = len(VIDEO_BIT_RATE)\n",
    "state = np.zeros((state_dim))\n",
    "action_vec = np.zeros(a_dim)\n",
    "action_vec[bit_rate] = 1\n",
    "s_info, s_len, c_len, total_chunk_num, bitrate_versions, \\\n",
    "    quality_penalty, rebuffer_penalty, smooth_penalty_p, smooth_penalty_n \\\n",
    "        = test_env.get_env_info()\n",
    "a_dim = len(bitrate_versions)\n",
    "\n",
    "# initialize recording files\n",
    "all_file_name = test_env.all_file_names\n",
    "log_path = log_path_ini + '_' + all_file_name[test_env.trace_idx]\n",
    "log_file = open(log_path, 'w')\n",
    "\n",
    "# start to download video\n",
    "for video_count in range(len(all_file_name)):\n",
    "    '''for a network trace '''\n",
    "    past_throughputs = np.zeros((1, 4))\n",
    "    states = torch.from_numpy(state).reshape(1, state_dim).to(device=device, dtype=torch.float32)\n",
    "    # states = torch.zeros((0, state_dim), device=device, dtype=torch.float32)\n",
    "    actions = torch.from_numpy(action_vec).reshape(1, a_dim).to(device=device, dtype=torch.float32)\n",
    "    # actions = torch.zeros((0, a_dim), device=device, dtype=torch.float32)\n",
    "    rewards = torch.zeros(0, device=device, dtype=torch.float32)\n",
    "    returns_est = torch.zeros(1, device=device, dtype=torch.float32).reshape(1, 1)\n",
    "    timesteps = torch.zeros(1, device=device, dtype=torch.long).reshape(1, 1)\n",
    "    time_stamp = 0\n",
    "    chunk_id = 0\n",
    "    while True:\n",
    "        delay, sleep_time, buffer_size, rebuf, \\\n",
    "            video_chunk_size, next_video_chunk_sizes, next_video_chunk_psnrs, \\\n",
    "                end_of_video, video_chunk_remain, _, curr_chunk_psnrs \\\n",
    "                    = test_env.get_video_chunk(bit_rate)\n",
    "        \n",
    "        time_stamp += delay  # in ms\n",
    "        time_stamp += sleep_time  # in ms\n",
    "\n",
    "        # reward is video quality - rebuffer penalty - smooth penalty\n",
    "        curr_quality = curr_chunk_psnrs[bit_rate]\n",
    "        sm_dif_p = max(curr_quality - last_quality, 0)\n",
    "        sm_dif_n = max(last_quality - curr_quality, 0)\n",
    "        reward = quality_penalty * curr_quality \\\n",
    "                    - rebuffer_penalty * rebuf \\\n",
    "                        - smooth_penalty_p * sm_dif_p \\\n",
    "                            - smooth_penalty_n * sm_dif_n \\\n",
    "                                - 2.661618558192494\n",
    "\n",
    "        last_bit_rate = bit_rate\n",
    "        last_quality = curr_quality\n",
    "\n",
    "        log_file.write(str(time_stamp / M_IN_K) + '\\t' +\n",
    "                    str(bitrate_versions[bit_rate]) + '\\t' +\n",
    "                    str(buffer_size) + '\\t' +\n",
    "                    str(rebuf) + '\\t' +\n",
    "                    str(video_chunk_size) + '\\t' +\n",
    "                    str(delay) + '\\t' +\n",
    "                    str(reward) + '\\n')\n",
    "        log_file.flush()\n",
    "\n",
    "        # ========== get action and reward ============\n",
    "        # add padding\n",
    "        actions = torch.cat([actions, torch.zeros((1, a_dim), device=device)], dim=0)\n",
    "        rewards = torch.cat([rewards, torch.zeros(1, device=device)])\n",
    "    \n",
    "        # ========== get state ============\n",
    "        BUFFER_NORM_FACTOR = 10.\n",
    "        state[0] = video_chunk_size / delay / M_IN_K  # kilo byte / ms # throughput\n",
    "        state[1] = float(buffer_size / BUFFER_NORM_FACTOR)  # 10 sec # buffer size\n",
    "        # last quality\n",
    "        # state[2] = parse[1] / float(np.max(ACTION_SELECTED))\n",
    "        state[2] = delay / M_IN_K  # chunk download time\n",
    "        state[3] = np.minimum(video_chunk_remain, total_chunk_num) / float(\n",
    "            total_chunk_num\n",
    "        )  # fraction of remaining chunks\n",
    "        state[4 : 4 + a_dim] = (\n",
    "            np.array(next_video_chunk_sizes) / M_IN_K / M_IN_K\n",
    "        )  # next chunk sizes\n",
    "        state[4 + a_dim : 4 + 2 * a_dim] = (\n",
    "            np.array(next_video_chunk_psnrs) / 100\n",
    "        )  # vmaf values [0, 100] # next chunk vmaf values\n",
    "\n",
    "        cur_state = torch.from_numpy(state).reshape(1, state_dim).to(device=device, dtype=torch.float32)\n",
    "        states = torch.cat([states, cur_state], dim=0)\n",
    "\n",
    "        # ========== get Qoe2Go prediction ============\n",
    "        # get observation of QoE2Go\n",
    "        throughput_current = video_chunk_size / delay / M_IN_K  # kilo byte / ms\n",
    "        throughput_mean, throughput_std = get_throughput_char(\n",
    "            past_throughputs, throughput_current\n",
    "        )\n",
    "        past_throughputs = np.roll(past_throughputs, -1, axis=1)\n",
    "        past_throughputs[0, -1] = throughput_current\n",
    "        buffer_size = float(buffer_size / BUFFER_NORM_FACTOR)  # 10 sec\n",
    "        remain_chunks_num = np.minimum(video_chunk_remain, total_chunk_num) / float(\n",
    "            total_chunk_num\n",
    "        )\n",
    "\n",
    "        # get QoE2Go estimation\n",
    "        q2go_obs = [throughput_mean, throughput_std, buffer_size, remain_chunks_num]\n",
    "        q2go_estimation = get_qoe2go_estimation(q2go_obs, q2go_model, device)\n",
    "        cur_return = torch.from_numpy(np.array([q2go_estimation])).reshape(1,1).to(device=device, dtype=torch.float32)\n",
    "        returns_est = torch.cat([returns_est, cur_return], dim=0)\n",
    "\n",
    "        timesteps = torch.cat([timesteps, torch.ones((1, 1), device=device, dtype=torch.long) * (chunk_id+1)], dim=1)\n",
    "\n",
    "\n",
    "        # ========== get action prediction ============\n",
    "        # get action inference\n",
    "        with torch.no_grad():\n",
    "            prob = dt_model.get_action(\n",
    "                states.to(dtype=torch.float32),\n",
    "                actions.to(dtype=torch.float32),\n",
    "                rewards.to(dtype=torch.float32),\n",
    "                returns_est.to(dtype=torch.float32),\n",
    "                timesteps.to(dtype=torch.long),\n",
    "            )\n",
    "        bit_rate = int(torch.argmax(prob).squeeze().cpu().numpy())\n",
    "\n",
    "        # set action\n",
    "        action_vec = np.zeros(a_dim)\n",
    "        action_vec[bit_rate] = 1\n",
    "        action_vec = torch.from_numpy(action_vec).to(device=device, dtype=torch.float32)\n",
    "        actions[-1] = action_vec\n",
    "        rewards[-1] = reward\n",
    "\n",
    "        chunk_id += 1\n",
    "\n",
    "        # end of video  \n",
    "        if end_of_video:\n",
    "            last_quality = test_env.chunk_psnr[DEFAULT_QUALITY][0]\n",
    "            state = np.zeros((state_dim))\n",
    "            action_vec = np.zeros(a_dim)\n",
    "            action_vec[DEFAULT_QUALITY] = 1\n",
    "            log_file.write('\\n')\n",
    "            log_file.close()\n",
    "            time_stamp = 0\n",
    "\n",
    "            if video_count + 1 >= len(all_file_name):\n",
    "                break\n",
    "            else:\n",
    "                log_path = log_path_ini + '_' + all_file_name[test_env.trace_idx]\n",
    "                log_file = open(log_path, 'w')\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     rewards\u001b[38;5;241m.\u001b[39mappend(\u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mmean(reward[\u001b[38;5;241m1\u001b[39m:]))\n\u001b[1;32m     16\u001b[0m rewards \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(rewards)\n\u001b[1;32m     18\u001b[0m rewards_min \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(rewards)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "rewards = []\n",
    "test_log_folder = './results_valid/'\n",
    "test_log_files = os.listdir(test_log_folder)\n",
    "for test_log_file in test_log_files:\n",
    "    reward = []\n",
    "    with open(test_log_folder + test_log_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            parse = line.split()\n",
    "            try:\n",
    "                reward.append(float(parse[-1]))\n",
    "            except IndexError:\n",
    "                break\n",
    "    rewards.append(np.mean(reward[1:]))\n",
    "\n",
    "rewards = np.array(rewards)\n",
    "\n",
    "rewards_min = np.min(rewards)\n",
    "rewards_5per = np.percentile(rewards, 5)\n",
    "rewards_mean = np.mean(rewards)\n",
    "rewards_median = np.percentile(rewards, 50)\n",
    "rewards_95per = np.percentile(rewards, 95)\n",
    "rewards_max = np.max(rewards)\n",
    "\n",
    "print(f\"rewards_min: {rewards_min}\")\n",
    "print(f\"rewards_5per: {rewards_5per}\")\n",
    "print(f\"rewards_mean: {rewards_mean}\")\n",
    "print(f\"rewards_median: {rewards_median}\")\n",
    "print(f\"rewards_95per: {rewards_95per}\")\n",
    "print(f\"rewards_max: {rewards_max}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
